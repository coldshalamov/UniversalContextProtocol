# MemGPT: Towards LLMs as Operating Systems

[Text Extracted from PDF 2310.11511v1.pdf]

MemGPT: Towards LLMs as Operating Systems

Charles Packer∗, Vivian Fang∗, Shishir G. Patil, Kevin Lin, Sarah Wooders, Joseph E. Gonzalez

Abstract
Large language models (LLMs) have revolutionized natural language processing, but their utility is often limited by a finite context window, which constrains their ability to handle long-term conversations or large documents. This paper proposes MemGPT (Memory-GPT), a system that manages LLM context as a multi-tier memory hierarchy, analogous to how operating systems manage physical and virtual memory. MemGPT enables LLMs to process context beyond their fixed window by providing them with tools to explicitly manage their own memory, including long-term storage and retrieval. We evaluate MemGPT on two domains that require extended context: multi-session chat and document analysis. Our results show that MemGPT can maintain long-term consistency in conversations and effectively retrieve information from large datasets, outperforming standard LLMs with fixed context windows.

... [Content Truncated]
