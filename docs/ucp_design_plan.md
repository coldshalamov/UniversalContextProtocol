# Optimal Design and Build Plan: Universal Context Protocol (UCP)

**Date:** January 8, 2026
**Generated by:** Gemini CLI Agent
**Status:** Proposed Architecture

---

## 1. Executive Summary

The **Universal Context Protocol (UCP)** is a proposed architectural solution to the "Tool Overload" problem in Agentic AI. As the Model Context Protocol (MCP) standardizes how Large Language Models (LLMs) connect to data and tools, a new bottleneck emerges: providing an LLM with access to thousands of tools simultaneously degrades performance, increases latency, and explodes context costs.

UCP functions as an **Intelligent Gateway**. To the end-user application (the MCP Client), UCP appears as a single, omnipotent MCP Server. Internally, however, UCP acts as a dynamic orchestrator that maintains connections to a vast fleet of downstream MCP servers. It uses a **predictive router**—trained via techniques like Retrieval-Augmented Fine-Tuning (RAFT)—to inject only the most relevant subset of tool schemas into the model's context window at any given moment.

This document outlines the optimal architecture, runtime behavior, and implementation roadmap for building UCP, synthesizing best practices from **Gorilla** (tool selection), **LangGraph** (state management), and **LlamaIndex** (context retrieval).

---

## 2. Problem Statement: The Context Bottleneck

Current MCP implementations rely on a static declaration of tools. If a user connects their Google Drive, Slack, GitHub, and Jira MCP servers, the LLM is flooded with hundreds of tool schemas (API definitions).

**Consequences:**
1.  **Recall Failure:** Models struggle to select the correct tool when "distractor" tools are present.
2.  **Context Bloat:** Massive schemas consume token budgets, pushing out conversation history.
3.  **Latency:** Processing huge system prompts increases time-to-first-token.
4.  **Cost:** Input tokens for irrelevant tools are billed on every turn.

**The UCP Solution:** Context-Aware Dynamic Injection.
Instead of ListTools() -> [All 500 Tools], UCP implements ListTools(context) -> [Top-5 Relevant Tools].

---

## 3. Architecture

UCP sits between the **MCP Client** (e.g., Claude Desktop, IDE) and the **Downstream MCP Servers**.

### 3.1 Component Diagram

`
[MCP Client] <===> [UCP Gateway] <===> [Downstream Fleet]
(Claude/Cursor)      |                   |
                     +-- Control Plane   +-- Stripe MCP
                     |   (Router/Index)  +-- Slack MCP
                     |                   +-- GDrive MCP
                     +-- Data Plane
                         (Proxy/Exec)
`

### 3.2 The Control Plane (The "Brain")

The Control Plane is responsible for deciding *what* the model sees.

1.  **The Tool Zoo (LlamaIndex):**
    *   A vector database (e.g., Qdrant, Milvus) storing the *schemas* and *descriptions* of every tool available in the Downstream Fleet.
    *   **Ingestion:** When a new MCP server is connected to UCP, its tools are fetched, parsed, and indexed. Metadata (domain, required permissions) is extracted.

2.  **The Router (Gorilla/RAFT):**
    *   A fine-tuned "Selector Model" (small, fast, e.g., Llama-3-8B-Gorilla) or a semantic router.
    *   **Input:** The last $ messages of conversation history + user intent.
    *   **Operation:** Performs a two-stage retrieval.
        *   *Stage 1:* Keyword/Semantic search against the Tool Zoo.
        *   *Stage 2:* Re-ranking/Filtering to select the minimal set (3-5 tools).
    *   **Output:** A list of ToolDefinition objects.

3.  **Session Manager (LangGraph):**
    *   Maintains the state of the conversation.
    *   Tracks the "Active Toolset" (what is currently injected).
    *   Decides when to trigger a re-route (e.g., topic shift detection).

### 3.3 The Data Plane (The "Body")

The Data Plane handles the actual traffic.

1.  **Virtual MCP Server:**
    *   Implements the MCP Protocol (JSON-RPC 2.0 over SSE/Stdio).
    *   **Intercepts** 	ools/list: Instead of forwarding to all servers, it queries the Control Plane for the Active Toolset and returns that.
    *   **Intercepts** 	ools/call: Routes the execution request to the specific downstream server that owns the tool.

2.  **Connection Pool:**
    *   Manages persistent connections (SSE) or spawns subprocesses (Stdio) for the downstream MCP servers.
    *   Handles authentication and error propagation.

---

## 4. Runtime Behavior: The "Loop"

The system operates in a cyclic loop managed by LangGraph.

**Step 1: User Message & Analysis**
*   User sends: "Check my last email for the invoice."
*   UCP intercepts the message.
*   **Router** embedding: "Check email", "invoice".
*   **Tool Zoo** retrieval: Returns gmail.list_messages, gmail.get_message.
*   **Router** filtering: Keeps Gmail tools. Discards github.create_issue.

**Step 2: Context Injection**
*   UCP constructs a 	ools/list response containing *only* the Gmail schemas.
*   The MCP Client (e.g., Claude) receives this list. To the client, it looks like only Gmail tools exist.

**Step 3: Inference & Execution**
*   The Client sends the context to the LLM.
*   LLM decides to call gmail.list_messages(query="invoice").
*   Client sends 	ools/call request to UCP.
*   UCP identifies the owner (Gmail MCP Server) and forwards the request.
*   Result is returned to the Client -> LLM.

**Step 4: Context Update (The "Cycle")**
*   LLM sees the email list: "I found invoice #1234. Should I pay it?"
*   User: "Yes, pay it."
*   **Router** detects topic shift ("pay").
*   **Tool Zoo** retrieval: Fetches stripe.create_charge.
*   **Context Update:** UCP silently updates the available tools. The next 	ools/list will include Stripe tools.

---

## 5. Critical Evaluation of Initial Ideas

*   **Single MCP Server Front:** *Confirmed.* This is the only way to maintain compatibility with existing clients (which expect a single endpoint or manual configuration).
*   **Predictive Tool Selection:** *Confirmed.* Essential. Without it, context limits are breached immediately.
*   **Bootstrapping via Heuristics:** *Recommended.* Start with simple semantic search (embedding similarity). Move to RAFT-tuned models only when logs are available.
*   **Injecting Top-N:** *Refined.* Instead of a hard N, use a "probability threshold". If 10 tools are highly relevant, show 10. If none, show none (or a general "search" tool).
*   **Context Bloat vs. Flexibility:** *Constraint.* UCP must balance these. "Paging out" tools is as important as paging them in.

---

## 6. Implementation Plan

### Phase 1: The Proxy (MVP)
*   **Goal:** Build the "Virtual Server" skeleton.
*   **Tech Stack:** Python (FastAPI/Starlette for SSE), MCP Python SDK.
*   **Deliverable:** A server that connects to *one* downstream MCP server and passes everything through. Proof of wiring.

### Phase 2: The Indexer
*   **Goal:** Create the Tool Zoo.
*   **Tech Stack:** LlamaIndex, ChromaDB/Qdrant.
*   **Action:** When the proxy starts, iterate through config-defined downstream servers. Call 	ools/list on each. Store schemas in the Vector DB.

### Phase 3: The Semantic Router
*   **Goal:** Dynamic 	ools/list.
*   **Tech Stack:** sentence-transformers (local embeddings).
*   **Logic:** Implement 	ools/list hook. Query Vector DB with the last user message. Return top-5 results.

### Phase 4: State & Persistence
*   **Goal:** Context continuity.
*   **Tech Stack:** LangGraph.
*   **Logic:** Wrap the Router in a LangGraph node. Save session state (which tools were active) so subsequent turns don't lose access to tools just because the user said "thanks".

### Phase 5: Advanced Routing (RAFT)
*   **Goal:** Accuracy.
*   **Action:** Collect logs from Phase 3. Use Gorilla's RAFT recipe to fine-tune a Llama-3-8B model to predict toolsets better than simple vector search.

---

## 7. Developer Ergonomics

*   **Config-Driven:** UCP should be configured via a simple ucp_config.yaml listing downstream servers (command/args or SSE URLs).
*   **Debug UI:** A local web dashboard (Streamlit/Panel) showing the current conversation state, active tools, and router confidence scores is essential for debugging "why did it pick that tool?".

## 8. Conclusion

UCP represents the necessary evolution of the MCP ecosystem. By decoupling "Available Tools" (The Fleet) from "Active Context" (The Window), UCP enables agents to scale to infinite capabilities without drowning in documentation. The architecture defined here leverages the strongest open-source components available today to make this vision a reality.
