# Gorilla: Large Language Model Connected with Massive APIs

[Text Extracted from PDF 2305.15334v1.pdf]

Gorilla: Large Language Model Connected with
Massive APIs

Shishir G. Patil1∗ Tianjun Zhang1,∗ Xin Wang2 Joseph E. Gonzalez1
1UC Berkeley 2Microsoft Research
sgp@berkeley.edu

Abstract
Large Language Models (LLMs) have seen an impressive wave of advances re-
cently, with models now excelling in a variety of tasks, such as mathematical
reasoning and program synthesis. However, their potential to effectively use tools
via API calls remains unfulfilled. This is a challenging task even for today’s state-of-
the-art LLMs such as GPT-4, largely due to their inability to generate accurate input
arguments and their tendency to hallucinate the wrong usage of an API call. We
release Gorilla, a finetuned LLaMA-based model that surpasses the performance
of GPT-4 on writing API calls. When combined with a document retriever, Gorilla
demonstrates a strong capability to adapt to test-time document changes, enabling
flexible user updates or version changes. It also substantially mitigates the issue of
hallucination, commonly encountered when prompting LLMs directly. To evaluate
the model’s ability, we introduce APIBench, a comprehensive dataset consisting
of HuggingFace, TorchHub, and TensorHub APIs. The successful integration of
the retrieval system with Gorilla demonstrates the potential for LLMs to use tools
more accurately, keep up with frequently updated documentation, and consequently
increase the reliability and applicability of their outputs. Gorilla’s code, model,
data, and demo are available at https://gorilla.cs.berkeley.edu

1 Introduction
Recent advances in large language models (LLMs) [10, 5, 32, 6, 29, 30] have enabled significant new
capabilities including natural dialogue, mathematical reasoning, and program synthesis. However,
despite these advances, LLMs are still fundamentally limited by the information they can store in a
fixed set of weights and the things they can compute using a static computation graph and limited
context. Furthermore, as the world changes, LLMs require retraining to update their knowledge and
reasoning capabilities.
By empowering LLMs to use tools [33], we can grant access to vastly larger and changing knowledge
bases and accomplish complex computational tasks. By providing access to search technologies and
databases, [26, 39, 37] demonstrated that we can augment LLMs to address a significantly larger
and more dynamic knowledge space. Similarly, by providing access to computational tools, [39, 2]
demonstrated that LLMs can accomplish complex computational tasks. Consequently, leading LLM
providers[29], have started to integrate plugins to allow LLMs to invoke external tools through APIs.

... [Content Truncated]
