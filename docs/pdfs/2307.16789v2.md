# Retooling LLMs: Generation with Integrated Document Retrieval and Tool-use
**Source:** 2307.16789v2.pdf

## Abstract
Large language models (LLMs) have shown significant promise in various tasks, but they still struggle with grounding their generations in factual information and performing complex reasoning that requires external tools. In this paper, we explore "Retooling LLMs" â€“ a paradigm where LLMs are equipped with both document retrieval capabilities and the ability to use external tools in an integrated manner. We present a framework that allows LLMs to retrieve relevant documents to provide context and then use tools (like calculators or search engines) to process that information or verify facts. Our results show that this integrated approach significantly improves performance on knowledge-intensive tasks and reduces hallucinations.

## 1 Introduction
LLMs are powerful but have limitations in factual accuracy and complex computation. Previous works have explored retrieval-augmented generation (RAG) and tool-use separately. However, many real-world tasks require a combination of both. For instance, answering a complex financial question might require retrieving the latest annual report and then using a calculator to compute growth rates.

## 2 Methodology
We propose an integrated architecture where the LLM can emit special tokens to trigger either a retrieval action or a tool call.
* **Integrated Retrieval:** The model searches a large corpus for relevant passages.
* **Tool-use:** The model calls external APIs for specific tasks.
* **Interleaved Execution:** The model can interleave these actions, using retrieved information as input to tools, and vice-versa.

## 3 Experiments
We evaluate our approach on several benchmarks, including HotpotQA, StrategyQA, and a newly curated set of "Complex Tool-use" tasks.
* **Results:** Our model consistently outperforms baselines that only use retrieval or only use tools.
* **Analysis:** We find that retrieval often provides the "what" (the raw data) while tools provide the "how" (the processing logic).

## Figures and Tables
* **Figure 1:** System architecture showing the LLM interacting with a retriever and a tool executor.
* **Table 1:** Performance comparison on various benchmarks.
* **Figure 2:** Examples of model trajectories interleaving retrieval and tool-use.
