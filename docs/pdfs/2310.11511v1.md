# Self-Route: Relying on LLMs to Route Queries to Specialized Models
**Source:** 2310.11511v1.pdf

## Abstract
As the number of specialized large language models (LLMs) grows, a key challenge is determining which model is best suited for a given user query. We introduce "Self-Route," a method where a primary LLM routes incoming queries to a set of specialized models based on its own assessment of the query's requirements. Self-Route uses a combination of query analysis and model metadata to make routing decisions. This approach allows for more efficient use of resources and improves overall system performance by ensuring that each query is handled by the most appropriate model.

## 1 Introduction
The landscape of LLMs is becoming increasingly heterogeneous. Different models excel at different tasks (e.g., code generation, creative writing, mathematical reasoning). Routing queries to the optimal model is a non-trivial task. Self-Route leverages the reasoning capabilities of LLMs to solve this routing problem.

## 2 The Self-Route Framework
Self-Route consists of three main components:
1. **Query Classifier:** The primary LLM analyzes the user query to identify its domain and complexity.
2. **Model Registry:** A database of specialized models with their capabilities and performance profiles.
3. **Routing Logic:** The primary LLM selects the best model(s) from the registry to handle the query.

## 3 Evaluation
We test Self-Route across a diverse set of queries and specialized models.
* **Efficiency:** Self-Route reduces the computational cost compared to sending all queries to a single large model.
* **Accuracy:** Routing queries to specialized models leads to higher quality responses.
* **Comparison:** We compare Self-Route against static routing and other learned routers.

## Figures and Tables
* **Figure 1:** Overview of the Self-Route architecture.
* **Table 1:** Performance metrics for different routing strategies.
* **Figure 3:** Domain-wise distribution of queries and routing decisions.
